# -*- coding: utf-8 -*-
# __author__ = 'xuanhongdong, qinjincheng'

from optparse import OptionParser
import pandas as pd
import os
from collections import Counter

parser = OptionParser(description='Filter PFAM DOMAIN generated by hmmer')
parser.add_option('-d', '--detail', dest='detail', help='input SNP detail file')
parser.add_option('-a', '--annotation', dest='annotation', help='input SNP annotation file')
parser.add_option('-o', '--output', dest='output', help='output directory containing resultant files')
(opts, args) = parser.parse_args()

def main(snp_detail, snp_annotation, dir_out):
    print 'INFO: start processing {}'.format(snp_detail)
    data_anno_pre = deal_snp_detail(snp_detail, dir_out)
    if os.path.getsize(data_anno_pre) > 0:
        print 'INFO: succeed in exporting {}'.format(data_anno_pre)
        snp_annot_stat = merge_snp_annot(data_anno_pre, snp_annotation, dir_out)
        if os.path.getsize(snp_annot_stat) > 0:
            print 'INFO: succeed in exporting {}'.format(snp_annot_stat)
        else:
            raise Exception('ERROR: fail to export {}'.format(snp_annot_stat))
    else:
        raise Exception('ERROR: fail to export {}'.format(data_anno_pre))

def deal_snp_detail(snp_detail, dir_out):
    snp_type_stat = dict()
    snp_pos_stat = dict()
    indel_pos_stat = dict()
    all_depth_stat = dict()
    all_freq_stat = dict()
    depth_list = ['<=30', '31-100', '101-200', '201-300', '301-400', '401-500', '>501']
    chroms = set()
    distributions = set()
    data_list = list()
    sample_old_index = list()
    sample_old_gene = list()
    with open(snp_detail) as f:
        sample_names = sorted(f.readline().strip().split('\t')[11:])
        for s in sample_names:
            snp_type_stat[s] = dict()
            snp_pos_stat[s] = dict()
            indel_pos_stat[s] = dict()
            all_freq_stat[s] = [0]
            all_depth_stat[s] = [0, 0, 0, 0, 0, 0, 0]
            sample_old_index.append(-1)
            sample_old_gene.append('')
        for line in f:
            if ';' in line:
                continue
            line = line.strip().split('\t')
            sample_infos = line[11:]
            new_gene_name = line[7]
            chroms.add(line[0])
            distributions.add(line[6])
            snp_type = '{}/{}'.format(line[3], line[4])
            data = {
                'type': 'snp' if len(line[3]) + len(line[4]) == 2 and '-' not in snp_type else 'indel',
                'chrom': line[0],
                'start': line[1],
                'end': line[2],
                'ref': line[3],
                'alt': line[4],
                'qual': float(line[5]),
                'reads_num': int(line[8]),
                'anno': line[6],
                'gene': line[7],
                'mut_type': line[9],
                'mut_info': line[10],
                'snp_type': snp_type
            }
            for n, s in enumerate(sample_names):
                rate = sample_infos[n]
                mut_rate = 0
                depth_num = -1
                single_and_all = '.'
                if rate != './.' and rate != '0/0':
                    single_and_all = rate.split('/')[1]
                    mut_rate = round(float(rate.split('/')[0]) / float(rate.split('/')[1]), 4)
                    if line[6] == 'exonic':
                        sample_old_index[n], all_freq_stat[s] = gene_num_stat(
                            new_gene_name, sample_old_gene[n], sample_old_index[n], all_freq_stat[s]
                        )
                        sample_old_gene[n] = new_gene_name
                    if not '-' in snp_type and len(snp_type) == 3:
                        snp_type_stat[s] = type_stat(snp_type, snp_type_stat[s])
                    depth_num = int(rate.split('/')[1])
                    if data['type'] == 'snp':
                        snp_pos_stat[s] = type_stat(data['anno'], snp_pos_stat[s])
                    else:
                        indel_pos_stat[s] = type_stat(data['anno'], indel_pos_stat[s])
                data['{}_mut_rate'.format(s)] = mut_rate
                data['{}_reads_rate'.format(s)] = single_and_all
                all_depth_stat[s] = get_depth_stat(depth_num, all_depth_stat[s])
            data_list.append(data)
    data_anno_pre = os.path.join(dir_out, 'data_anno_pre.xls')
    df_data_list_pre = pd.DataFrame(data_list)
    df_data_list_pre.to_csv(data_anno_pre, sep='\t', header=True, index=False)
    depth_data = get_stat_data(sample_names, depth_list, all_depth_stat, 'depth_stat')
    df_depth = pd.DataFrame(depth_data)
    df_depth.to_csv(os.path.join(dir_out, 'snp_depth_statistics.xls'), sep='\t', header=True, index=False)
    new_freq_stat = freq_stat(all_freq_stat)
    freq_data = get_stat_data(sample_names, [1, 2, 3, 4, '>=5'], new_freq_stat, 'freq_stat')
    freq_data = pd.DataFrame(freq_data)
    freq_data.to_csv(os.path.join(dir_out, 'snp_freq_statistics.xls'), sep='\t', header=True, index=False)
    snp_types = ['A/G', 'A/C', 'C/T', 'G/A', 'G/C', 'C/A', 'A/T', 'C/G', 'G/T', 'T/C', 'T/A', 'T/G']
    type_data = get_stat_data(sample_names, snp_types, snp_type_stat, 'type_stat')
    type_data = pd.DataFrame(type_data)
    type_data.to_csv(
        os.path.join(dir_out, 'snp_transition_tranversion_statistics.xls'), sep='\t', header=True, index=False
    )
    snp_pos_data = get_stat_data(sample_names, list(distributions), snp_pos_stat, 'snp_distribution')
    snp_pos_data = pd.DataFrame(snp_pos_data)
    snp_pos_data.to_csv(os.path.join(dir_out, 'snp_position_distribution.xls'), sep='\t', header=True, index=False)
    indel_pos_data = get_stat_data(sample_names, list(distributions), indel_pos_stat, 'indel_distribution')
    indel_pos_data = pd.DataFrame(indel_pos_data)
    indel_pos_data.to_csv(os.path.join(dir_out, 'indel_position_distribution.xls'), sep='\t', header=True, index=False)
    print distributions
    with open(os.path.join(dir_out, 'main_info.txt'), 'w') as w:
        w.write('snp_types\t{}\n'.format(';'.join(snp_types)))
        w.write('specimen\t{}\n'.format(';'.join(sample_names)))
        w.write('distributions\t{}\n'.format(';'.join(list(distributions))))
        w.write('chroms\t{}\n'.format(';'.join(list(chroms))))
    return data_anno_pre

def get_depth_stat(depth_num, target_list):
    if depth_num == -1:
        pass
    else:
        if depth_num < 31:
            target_list[0] += 1
        elif 30 < depth_num < 101:
            target_list[1] += 1
        elif 100 < depth_num < 201:
            target_list[2] += 1
        elif 200 < depth_num < 301:
            target_list[3] += 1
        elif 300 < depth_num < 401:
            target_list[4] += 1
        elif 400 < depth_num < 501:
            target_list[5] += 1
        else:
            target_list[6] += 1
    return target_list

def type_stat(dict_key, target_dict):
    if dict_key in target_dict:
        target_dict[dict_key] += 1
    else:
        target_dict[dict_key] = 1
    return target_dict

def get_stat_data(sample_names, range_list, value_dict, stat_type):
    stat_data = list()
    for n, ds in enumerate(range_list):
        data = {'range_key': ds, 'stat_type': stat_type}
        for s in sample_names:
            if type(value_dict[s]) is list:
                data[s] = value_dict[s][n]
            else:
                if ds not in value_dict[s].keys():
                    value_dict[s][ds] = 0
                data[s] = value_dict[s][ds]
        stat_data.append(data)
    return stat_data

def gene_num_stat(new_gene_name, old_gene_name, old_index, new_list):
    if new_gene_name == old_gene_name:
        new_list[old_index] += 1
    else:
        new_list.append(1)
        old_index += 1
    return old_index, new_list

def freq_stat(all_freq_stat):
    for s in all_freq_stat:
        c = Counter(all_freq_stat[s])
        values = c.values()
        keys = c.keys()
        d = {'>=5': 0}
        for n, k in enumerate(keys):
            if k < 5:
                d[k] = values[n]
            else:
                d['>=5'] += values[n]
        all_freq_stat[s] = d
    return all_freq_stat

def merge_snp_annot(data_anno_pre, snp_annotation, dir_out):
    df_dap = pd.read_table(data_anno_pre, header=0, sep='\t', low_memory=False)
    tmp_list = df_dap.columns[:-14].tolist()
    tmp_list.append(df_dap.columns[-1])
    df_dap_select = df_dap.loc[:, tmp_list]
    df_dap_select['index1'] = df_dap['alt'].apply(str) + df_dap['anno'].apply(str) + df_dap['chrom'].apply(str) + \
                              df_dap['end'].apply(str) + df_dap['start'].apply(str) + df_dap['ref'].apply(str)
    df_sn = pd.read_table(snp_annotation, header=0, sep='\t', low_memory=False)
    df_sn_tmp = df_sn.loc[:, df_sn.columns[:13]]
    df_sn_tmp.rename(columns={
        'Depth': 'Total depth', 'CHROM': 'Chrom', 'ALT': 'Alt', 'ANNO': 'Anno', 'END': 'End',
        'START': 'Start', 'REF': 'Ref', 'MUT_type': 'MUT type', 'MUT_info': 'MUT info'
    }, inplace=True)
    df_sn_select = df_sn_tmp[[
        'GENE(in or nearby)', 'Gene name', 'Gene description', 'Chrom', 'Start', 'End', 'Ref',
        'Alt', 'Total depth', 'QUAL', 'Anno', 'MUT type', 'MUT info']]
    df_sn_select['index1'] = df_sn['ALT'].apply(str) + df_sn['ANNO'].apply(str) + df_sn['CHROM'].apply(str) + \
                             df_sn['END'].apply(str) + df_sn['START'].apply(str) + df_sn['REF'].apply(str)
    df_merge = pd.merge(df_sn_select, df_dap_select, on='index1', how='outer')
    df_merge.drop(columns=['index1'], inplace=True)
    snp_annot_stat = os.path.join(dir_out, 'snp_annotation_statistics.xls')
    df_merge.to_csv(snp_annot_stat, sep='\t', index=False)
    return snp_annot_stat

if __name__ == '__main__':
    if opts.detail and opts.annotation and opts.output:
        main(opts.detail, opts.annotation, opts.output)
    else:
        parser.print_help()